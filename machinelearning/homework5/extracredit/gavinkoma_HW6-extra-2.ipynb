{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 6, Part 2:   Recurrent Neural Networks (RNN)  -- Extra Credit (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to model sequential data such as sentences, documents and videos, etc, the state of the art approach is to use Recurrent neural network (RNN). At each timestep, RNN takes an element (such as a word) as input, combines with past information encoded as a vector (such as all information in the sentence before this timestep), generate a new vector encoding both current input and past information, then delivers it to next timestep.\n",
    "\n",
    "For more details about LSTM (a very popular variant of RNN), please refer to http://colah.github.io/posts/2015-08-Understanding-LSTMs/ and here is a very good video explaining RNN: https://www.youtube.com/watch?v=WCUNPb-5EYI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with Long Short-Term Memory Networks\n",
    "\n",
    "RNN can be used to generate text. For more information, please read: https://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n",
    "\n",
    "The following is an example script to generate text from Nietzsche's writings.\n",
    "\n",
    "Note: \n",
    "- At least 10 epochs are required before the generated text\n",
    "starts sounding coherent, but more is better.\n",
    "\n",
    "- It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "- If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries \n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "#Get the data - available from amazon\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower() # make it all lowercase \n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 120171\n",
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b99405cc524d>:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "<ipython-input-3-b99405cc524d>:20: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cut the text in semi-redundant sequences of maxlen characters\n",
    "## Cut the text into a series of windows. \n",
    "## Each window is 40 characters\n",
    "## The window moves 3 steps forward each step\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "# Turn these sentances into one-hot encoded vectors\n",
    "## For all words in the sentances, there is a one, else there is a zero in that index of the vector\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have data to feed a model for text generation. Next  we build a LSTM model to fit the data. Using Keras this is only few lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.ma.log(preds)\n",
    "    preds = preds.filled(0)\n",
    "    preds = preds / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # clear_output()\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % (epoch+1))\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.4, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "-  Each epoch takes up to 1 minute or so on a CPU (an epoch took 30 seconds for my PC)\n",
    "-  Recall that training on at least 20 epochs will give intelligible results \n",
    "-  So you're gonna have to let this run for a while (if ETA per epoch is bigger than 5 minutes on your machine, you can reduce the number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model\n",
    "Since it is time consuming to train this LSTM model with CPU for more epochs, we provided a pre-trained model which is trained on GPU for 100 epochs. Use the following code to check how coherency the model is.\n",
    "\n",
    "It requires h5py packages, please install it to test the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained model...\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"from an anguish with which no other is t\"\n",
      "from an anguish with which no other is the more and such a really the subjection of the subjection of the fact the sense of the fact the present the subjection and all the subjection of the sense of the state to the serve the conscious and such a particularly the subjection of the more and such a man is a man and the capacity, and in the subjection of the present the consciousness, and a subjection of the possible who have not all the p\n",
      "----- diversity: 0.3\n",
      "----- Generating with seed: \"from an anguish with which no other is t\"\n",
      "from an anguish with which no other is the things of the so the consequ: at the preserves of the seecless, which has been a science, to be perceive the rest in the fact the fact, and we cannot be called the fact the self--and when the subjection that the constitute of the such the subjection of the reality, and the particularly the morality and the subjection of the probably in the soul the subjection of the possible would be such a pro\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"from an anguish with which no other is t\"\n",
      "from an anguish with which no other is the master philosophers when it is more every happen the same necessary that the world and shame\" it such morality to this hors should is the finally\n",
      "faith and the subjections of men, so the nature. the state of the cape man is also the sense of\n",
      "christian serves of the sympathy and a command in spectably more that the \"indivisure of the first in order to the still man, who is to particular, and a m\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"from an anguish with which no other is t\"\n",
      "from an anguish with which no other is tyrann opposition see us, such morality are\n",
      "things. the reded cannstinction only to the solled no one inversigates, to make the genuation it own for him, fact as immuliayces in\n",
      "realsor of chriftlys excertious one extent in eternalty\n",
      "as deveryore, a revolution. it deveated; not the redyentions is\n",
      "these, as ipearing\n",
      "is cay urture! the hearts of commanding and\n",
      "reality un\"fnempousing\", in ready, as dis\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Load pre-trained model...')\n",
    "from keras.models import load_model\n",
    "model = load_model('shakespear200.h5')\n",
    "\n",
    "\n",
    "def lstm_generate(seed, model):\n",
    "    orig_seed = seed\n",
    "    for diversity in [0.2, 0.3, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "        seed = orig_seed\n",
    "        generated = ''\n",
    "        generated += seed\n",
    "        print('----- Generating with seed: \"' + seed + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(seed):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            seed = seed[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "\n",
    "seed = \"from an anguish with which no other is t\"\n",
    "# seed = \"thou art\"\n",
    "lstm_generate(seed, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: use LSTM to generate baby names\n",
    "-  The following data set contains 8000 last names. You can download and process the name data set as follows:\n",
    "\n",
    "```python\n",
    "name_path = get_file('names.txt', origin='http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/other/names.txt')\n",
    "with io.open(name_path, encoding='utf-8') as f:\n",
    "    text = f.read() # make it all lowercase \n",
    "    \n",
    "text = text.split()\n",
    "text = ', '.join(text)\n",
    "```\n",
    "\n",
    "Using the last name data set, answer the following questions:\n",
    "\n",
    "1. (30 points) Train a LSTM to generate the names. How long does it take to train? How coherent does it sound? \n",
    "2. (10 points) Can you train the LSTM, but for every epoch, shuffle the order of names before call model.fit()? How long does it take to train? Does it improve the coherency?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 58\n",
      "nb sequences: 100350\n",
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-909763d2fc7d>:54: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "<ipython-input-8-909763d2fc7d>:55: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Build model...\n",
      "Done!\n",
      "Epoch 1/10\n",
      "783/784 [============================>.] - ETA: 0s - loss: 1.6766\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"Montag, Montagna, Montagne, Montagnino, \"\n",
      "Montag, Montagna, Montagne, Montagnino, Montane, Montaro, Montar, Montar, Montaro, Montaro, Montalli, Montartt, Montart, Montaro, Montarto, Montalla, Montaro, Montarto, Montart, Montarto, Montaro, Montarico, Montaro, Montarte, Montan, Montan, Montarie, Montarte, Montarico, Montari, Montarte, Montarta, Montarton, Montarta, Montarie, Montardo, Montart, Montaria, Montaro, Montari, Montaro, Montaro, Montarte, Montart, Montari, Montarton, Mo\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"Montag, Montagna, Montagne, Montagnino, \"\n",
      "Montag, Montagna, Montagne, Montagnino, Montalle, Montarciner, Montarina, Montans, Montarto, Montero, Montan, Montzer, Montana, Montarico, Montalla, Montan, Monthauss, Montaring, Montana, Montara, Montarie, Montara, Montarda, Montaria, Montant, Montzer, Montarci, Montane, Montaron, Monter, Montan, Montaro, Montaro, Montarter, Montarte, Montarie, Monta, Montarta, Montarton, Montallie, Montarie, Montaro, Montar, Montaris, Montara, Montari\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"Montag, Montagna, Montagne, Montagnino, \"\n",
      "Montag, Montagna, Montagne, Montagnino, Monthart, Monthartte, Monteraun, Montara, Monterauson, Monthertco, Montortte, Motterto, Motterowski, Motteroust, Mottratte, Mothant, Mothan, Mocher, Mochar, Mochar, Mochanto, Mochart, Mochane, Mochaule, Mocarch, Moca, Mocas, Mocanar, Mocara, Mocallice, Mocaro, Mocalle, Mocartte, Mocale, Mocarch, Mocatterice, Mocceros, Moccarica, Mocatte, Mocake, Mocale, Mocale, Mocardace, Mocanbaca, Mocarch, Mocar\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"Montag, Montagna, Montagne, Montagnino, \"\n",
      "Montag, Montagna, Montagne, Montagnino, Monaule, Monanrain, Monaston, Mosidetta, Moschueth, Morchdi, Morkdr, Mordgeson, Mordeve, Morper, Morreck, Morrank, Morrancci, Morral, Morron, Morrpa, Morrbs, Morros, Morret, Morra, Morrfauste, Morryre, Morrymer, Morzry, Morramak, Morran, Morrath, Moratli, Morauetto, Morawa, Morakliane, Morafi, Moratena, Moraser, Moratts, Morabele, Moarebaugh, Moarahteco, Moarce, Moarhyue, Moratteo, Moraki, Moranca\n",
      "784/784 [==============================] - 104s 131ms/step - loss: 1.6759\n",
      "Epoch 2/10\n",
      "783/784 [============================>.] - ETA: 0s - loss: 0.9908\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rting, Hartinger, Hartis, Hartje, Hartke\"\n",
      "rting, Hartinger, Hartis, Hartje, Hartke, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"rting, Hartinger, Hartis, Hartje, Hartke\"\n",
      "rting, Hartinger, Hartis, Hartje, Hartke, Harther, Harthar, Harther, Harther, Harther, Hartan, Hartana, Hartanski, Harthen, Harther, Harthart, Harthall, Harther, Harther, Harthing, Harthing, Harthi, Harting, Hartine, Hartinger, Harthor, Hartham, Harther, Hartin, Harting, Harton, Harton, Harton, Harton, Harton, Harton, Hartune, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Hart, Hartan, Hartan, Hartan, H\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rting, Hartinger, Hartis, Hartje, Hartke\"\n",
      "rting, Hartinger, Hartis, Hartje, Hartke, Hartena, Harten, Harten, Hartell, Harten, Hartentan, Hartelle, Hartella, Hartell, Hartelli, Harter, Harten, Harten, Harter, Hartell, Hartelli, Harthell, Harther, Harthan, Hartick, Harting, Harthala, Harthar, Harthian, Harting, Hartino, Harton, Harton, Harton, Hartond, Harton, Harton, Harton, Harton, Harton, Harton, Harton, Hartuli, Hartoro, Harton, Harton, Harton, Harton, Harton, Harton, Hartoo,\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rting, Hartinger, Hartis, Hartje, Hartke\"\n",
      "rting, Hartinger, Hartis, Hartje, Hartkey, Harsanda, Harsander, Haras, Haratoma, Harazele, Harazato, Harba, Harcenia, Harceny, Harchell, Harcher, Harchian, Harci, Harchopp, Harchuman, Harchrone, Hardruon, Harpteari, Harra, Harramauri, Harran, Harrick, Harrild, Harriman, Harori, Harrika, Harrina, Harrio, Harson, Harsmai, Harsming, Harssboe, Harsduss, Harmer, Harmanger, Harmandar, Harnard, Harnami, Harncen, Harnesski, Harnera, Harnet, Har\n",
      "784/784 [==============================] - 102s 130ms/step - loss: 0.9907\n",
      "Epoch 3/10\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.8916\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n, Bachmeier, Bachner, Bachrach, Bachtel\"\n",
      "n, Bachmeier, Bachner, Bachrach, Bachtel, Bachley, Bachlin, Bachlin, Bachling, Bachling, Bachling, Back, Backe, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backer, Backerson, Backerson, Backerson, Backerson, Backers, Backert, Backers, Backerson, Backerson, Backer, Backer, Backer, Backer, Backer, Bac\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"n, Bachmeier, Bachner, Bachrach, Bachtel\"\n",
      "n, Bachmeier, Bachner, Bachrach, Bachtel, Bacholi, Back, Backe, Backer, Backin, Backin, Backin, Backley, Backling, Backling, Backling, Backley, Backling, Backlin, Backlin, Backlin, Backling, Backlind, Backley, Backley, Backlin, Backley, Backlin, Backlin, Backlin, Backley, Backlin, Backley, Backlin, Backlin, Backling, Backlin, Backlin, Backlin, Backlin, Backlin, Backley, Backlon, Backley, Backlin, Backley, Backlin, Backlin, Backley, Back\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n, Bachmeier, Bachner, Bachrach, Bachtel\"\n",
      "n, Bachmeier, Bachner, Bachrach, Bachtel, Bachley, Bachling, Back, Backa, Backe, Backe, Backen, Backell, Backer, Backer, Backer, Backer, Backett, Backey, Backer, Backer, Backler, Backlin, Backlin, Backlon, Backley, Backlin, Backman, Backman, Backlen, Backler, Backley, Backley, Backlin, Backling, Backlin, Backlin, Backlin, Backling, Backlett, Backley, Backling, Backley, Backlin, Backlin, Backlon, Backman, Backley, Backling, Backling, Bac\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n, Bachmeier, Bachner, Bachrach, Bachtel\"\n",
      "n, Bachmeier, Bachner, Bachrach, Bachtel, Bachs, Bachbue, Bacham, Bachirna, Baccolia, Bacbstiello, Baccaltam, Baccarine, Baccataristei, Bacch, Bacchol, Baccow, Bacora, Bacocleso, Baceks, Back, Backen, Backow, Backin, Backoviell, Backman, Backley, Backling, Backlin, iadl, Tams, Bams, Tama, Tamala, Tamann, Taman, Tamadein, Taman, Tamaks, Tamardo, Tamar, Tamafar, Tamakrock, Tamar, Tamern, Tamer, Tamp, Tamper, Tampreghr, Tamplinger, Tampl, \n",
      "784/784 [==============================] - 103s 132ms/step - loss: 0.8916\n",
      "Epoch 4/10\n",
      "783/784 [============================>.] - ETA: 0s - loss: 0.8331\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ton, Hambley, Hamblin, Hambly, Hambrick,\"\n",
      "ton, Hambley, Hamblin, Hambly, Hambrick, Hambrick, Hambr, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberry, Hambert, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Ham\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"ton, Hambley, Hamblin, Hambly, Hambrick,\"\n",
      "ton, Hambley, Hamblin, Hambly, Hambrick, Hamberg, Hamberger, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hamberg, Hambert, Hamberg, Hamberg, Hamberg, Hamberry, Hamberg, Hamberg, Hamberg, Hamberg, Hamberry, Hambers, Hambert, Hambert, Hamberg, Hamberg, Hamberg, Hamberg, Hamber, Hamberg, Hamberg, Hamberg, Hamberg, Hamber, Hamberg, Hamberg, Hamberg, Hamberry, Hambie, Hambing, Hambi, Hamick, Hamin, Hamin, Hamin, Hamines, Hamins, Hamin, Hami\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ton, Hambley, Hamblin, Hambly, Hambrick,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ton, Hambley, Hamblin, Hambly, Hambrick, Hamberger, Hambert, Hamberry, Hamberger, Hamberg, Hamberg, Hamberg, Hamberry, Hambergh, Hamberger, Hamberger, Hamberrick, Hamberger, Hambers, Hambert, Hambert, Hamber, Hambert, Hamberg, Hamberg, Hamberner, Hamberg, Hamberg, Hamberg, Hamberger, Hamberg, Hambert, Hambert, Hamber, Hamberr, Hamberg, Hamberg, Hamberg, Hamberger, Hambert, Hambert, Hamberg, Hamberg, Hamberger, Hamberg, Hamberger, Hamber\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ton, Hambley, Hamblin, Hambly, Hambrick,\"\n",
      "ton, Hambley, Hamblin, Hambly, Hambrick, Hamberg, Hamberry, Haldin, Haldin, Halding, Haldin, Haldh, Haldemun, Halder, Halenear, Halenke, Halent, Halen, Halen, Halen, Halened, Halent, Hales, Hales, Halese, Halesz, Hall, Hall, Halla, Halleabia, Hallenburw, Hallena, Hallener, Hallenill, Hallen, Hallenzell, Hallens, Hallesing, Hallis, Hallison, Hallmier, Hallmes, Hallpon, Hallone, Halmon, Halmo, Halmman, Halmo, Halmura, Halomson, Halmour, H\n",
      "784/784 [==============================] - 104s 133ms/step - loss: 0.8332\n",
      "Epoch 5/10\n",
      "783/784 [============================>.] - ETA: 0s - loss: 0.7888\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"eri, Carper, Carpinelli, Carpino, Carpio\"\n",
      "eri, Carper, Carpinelli, Carpino, Carpio, Carpine, Carpin, Carpine, Carpine, Carpine, Carpine, Carpin, Carpine, Carpine, Carpine, Carpino, Carpine, Carpin, Carpin, Carpine, Carpin, Carpin, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpino, Carpine, Carpine, Carpine, Carpine, Carpine, Carpine, Carpino, Carpine, Carpine, Carpino, Carpino, Carpine, Carpino, Carpino, Carpine,\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"eri, Carper, Carpinelli, Carpino, Carpio\"\n",
      "eri, Carper, Carpinelli, Carpino, Carpio, Carpine, Carpin, Carpino, Carpin, Carpine, Carpino, Carpino, Carpoli, Carpon, Carpon, Carpon, Carpon, Carpoli, Carpolin, Carpone, Carporo, Carpora, Carpore, Carpona, Carpon, Carpon, Carpon, Caro, Caron, Carone, Carone, Caron, Caron, Carone, Carone, Caronce, Carone, Carone, Carone, Carone, Carone, Caron, Carone, Carone, Caron, Carone, Carone, Carone, Carone, Carone, Carone, Carone, Carone, Caroni\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"eri, Carper, Carpinelli, Carpino, Carpio\"\n",
      "eri, Carper, Carpinelli, Carpino, Carpio, Carpino, Carpon, Carpon, Carpana, Carpan, Carpan, Carpante, Carpan, Carparia, Carpan, Carpan, Carparie, Carparin, Carparilla, Carpeara, Carpel, Carpella, Carpella, Carpella, Carpella, Carpen, Carpella, Carpella, Carpel, Carpella, Carpelli, Carpelli, Carpella, Carpella, Carpelli, Carpelin, Carpella, Carpelli, Carpella, Carpella, Carpeline, Carpelli, Carpella, Carpella, Carpeline, Carpenich, Carpe\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"eri, Carper, Carpinelli, Carpino, Carpio\"\n",
      "eri, Carper, Carpinelli, Carpino, Carpio, Carplon, Carponacchi, Carpon, Carpron, Carpett, Carpey, Carpetts, Carpina, Carppelma, Carpnohni, Carpoleso, Carpner, Carnaer, Carnatt, Carnen, Carnenan, Carneman, Carnian, Carnieri, Carnig, Carni, Carnice, Criner, Carime, Cariner, Carnington, Crono, Cnarn, Canron, Carnin, Carnnie, Carno, Carnt, Carnton, Cartz, Cartze, Carzo, Carzet, Carzie, Cazt, Cazai, Cada, Caaduna, Cabico, Cadel, Cadenbach, C\n",
      "784/784 [==============================] - 103s 132ms/step - loss: 0.7888\n",
      "Epoch 6/10\n",
      "783/784 [============================>.] - ETA: 0s - loss: 0.7555\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"an, Bedsaul, Bedsole, Bedwell, Bee, Beeb\"\n",
      "an, Bedsaul, Bedsole, Bedwell, Bee, Beebel, Beebel, Beebel, Beebel, Beebel, Beebel, Beebel, Beebel, Beebell, Beeber, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert,\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"an, Bedsaul, Bedsole, Bedwell, Bee, Beeb\"\n",
      "an, Bedsaul, Bedsole, Bedwell, Bee, Beebel, Beebel, Beebel, Beebel, Beeber, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beeber, Beebert, Beebert, Beebers, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebers, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebe\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"an, Bedsaul, Bedsole, Bedwell, Bee, Beeb\"\n",
      "an, Bedsaul, Bedsole, Bedwell, Bee, Beebel, Beebel, Beebel, Beebel, Beebelle, Beebelber, Beeber, Beeben, Beeber, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beebert, Beeberry, Beebert, Beebert, Beebert, Beebert, Beebers, Beebert, Beebert, Beebert, Beebert, Beebers, Beebert, Beebert, Beebert, Beebert, Beebert, Beeben, Beebers, Beebert, Beebert, Beeberter, Beebertier, Beebert, Beebert, Beebert\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"an, Bedsaul, Bedsole, Bedwell, Bee, Beeb\"\n",
      "an, Bedsaul, Bedsole, Bedwell, Bee, Beebel, Beeben, Beebel, Beebelka, Beebens, Beeber, Beebne, Beedr, Beedro, Beeipanle, Beek, Beekoff, Beeklinger, Beeklinger, Belekinger, Belker, Belles, Bellahrune, Bellene, Belleter, Belletna, Bellette, Bellette, Bellette, Bellett, Bellf, Bellforf, Bellford, Bellvergets, Bellhorfer, Bellish, Bellik, Bellile, Bellika, Bellimer, Bellimarrro, ,ellison, Gelly, Gelpich, Gelmell, Gelpell, Gelpel, Gelp, Gelp\n",
      "784/784 [==============================] - 102s 130ms/step - loss: 0.7557\n",
      "Epoch 7/10\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.7240\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"el, Buckelew, Buckels, Buckey, Buckhalte\"\n",
      "el, Buckelew, Buckels, Buckey, Buckhalter, Buckler, Buckling, Bucklon, Bucklon, Buckler, Bucklon, Buckley, Bucklon, Bucklon, Bucklon, Buckler, Buckler, Bucklon, Bucklon, Bucklon, Buckley, Bucklon, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Buckler, Buckley, Bucklon, Bucklon, Bucklon, Bucklon, Buckler, Buckler, Bucklon, Bucklon, Bucklon, Buckler, \n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"el, Buckelew, Buckels, Buckey, Buckhalte\"\n",
      "el, Buckelew, Buckels, Buckey, Buckhalter, Bucki, Buckle, Buckley, Bucklon, Bucklon, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Bucklon, Buckler, Buckling, Buckler, Bucklon, Bucklon, Bucklon, Buckling, Buckler, Bucklon, Bucklon, Buckler, Bucklon, Buckman, Bucklon, Buckler, Buckley, Bucklon, Bucklon, Bucklon, Buckling, Buckley, Bucklon, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Bucklon, Buckler, Buckler, Bucklon, Buckling, Buckling,\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"el, Buckelew, Buckels, Buckey, Buckhalte\"\n",
      "el, Buckelew, Buckels, Buckey, Buckhalter, Bucks, Buckstan, Bucklow, Buckling, Buckler, Buckley, Bucklon, Bucklon, Bucklon, Bucklon, Bucklon, Buckley, Bucklon, Bucklon, Bucklon, Bucklon, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Buckler, Bucklon, Bucklon, Buckler, Buckley, Buckling, Bucklon, Bucklon, Buckman, Buckmer, Buckling, Buckley, Bucklon, Bucklon, Bucklon, Buckler, Buckler, Bucklon, Buckling, Buckler, Bucklon, Buckler, Bucklon\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"el, Buckelew, Buckels, Buckey, Buckhalte\"\n",
      "el, Buckelew, Buckels, Buckey, Buckhalte, Buchlen, Buchman, Buchies, Buchmain, Buchley, Buchlile, Buchlinger, Bucglin, Buckler, Bucklings, Buckling, Buckman, Bucklone, Bucku, Buck, Buckenberger, Bucker, Buckerton, Bucker, Bucker, Buckert, Buckesen, Buckert, Buckerson, Buckers, Buckerton, Buckerhing, Buckert, Bucketty, Buckloff, Bucklond, Bucklinger, Bucklon, Bucklon, Buckling, Buckler, Bucklein, Bucklinler, Bucklinger, Buckman, Buckman,\n",
      "784/784 [==============================] - 102s 130ms/step - loss: 0.7240\n",
      "Epoch 8/10\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.6979\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"t, Voigts, Voiles, Voisin, Voisine, Voit\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t, Voigts, Voiles, Voisin, Voisine, Voit, Voith, Voith, Voith, Voither, Voither, Voither, Vother, Votherson, Votherson, Votherson, Vothert, Vothhers, Vothmer, Vothming, Vothols, Vothole, Vothole, Vothols, Vothole, Vothole, Vothole, Vothole, Vothole, Vothold, Vothold, Vothold, Vothon, Vottier, Vottinger, Votting, Vottinger, Vottinge, Vottinger, Vottinge, Vottinger, Vottinski, Vottin, Vottinsco, Vottier, Vottinger, Vottinge, Votting, Vott\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"t, Voigts, Voiles, Voisin, Voisine, Voit\"\n",
      "t, Voigts, Voiles, Voisin, Voisine, Voit, Voith, Voith, Voigh, Voigh, Voigh, Voighton, Voight, Voight, Voight, Voighton, Voighton, Voighton, Voighton, Voigson, Voits, Voit, Voitzel, Voig, Voines, Voinette, Voineston, Voinetti, Vointer, Vointer, Vointhan, Vointine, Vointine, Vointing, Vointing, Vointinger, Vointz, Vointzen, Vointz, Vointzeau, Vointz, Vointzen, Vointzen, Vointz, Vointze, Vointz, Vointzen, Vointzen, Vointze, Vointzer, Voin\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"t, Voigts, Voiles, Voisin, Voisine, Voit\"\n",
      "t, Voigts, Voiles, Voisin, Voisine, Voiter, Voith, Voith, Voither, Voither, Voithers, Voith, Voither, Vioh, Vioh, Viohne, Vioker, Viokowski, Viokson, Vios, Viot, Viover, Viofria, Vionice, Vioping, Vipone, Vipp, Vippa, Vippart, Vipper, Vipper, Vippert, Vippette, Vippette, Vippins, Vipping, Vippa, Vippare, Vipp, Vippard, Vippa, Vippart, Vippers, Vippert, Vippert, Vippin, Vippotta, Vippos, Vipps, Vippssie, Vipster, Vipston, Vipst, Vipton, \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"t, Voigts, Voiles, Voisin, Voisine, Voit\"\n",
      "t, Voigts, Voiles, Voisin, Voisine, Voiter, Vjierann, Vihras, Vihrsen, Vihrinco, Vihronti, Viksfe, Vikwell, Vikwain, Vix, Vifore, Vifpenkurn, Vifforff, Viffy, Vifrieta, Vifrostra, Vifrette, Vigrenstra, Vigriand, Vigrina, Vigrts, Vigzor, Vigser, Vigutus, Vigon, Viguide, Vigesson, Viggsore, Viggin, Vignies, Vigmon, Viglow, igglel, Iggley, Iggman, Iggmel, Iggore, Iggonn, Igwell, Igoss, Iguva, Igyl, Igsora, Igt, Igyg, Itzel, Itzall, Iu, Iu,\n",
      "784/784 [==============================] - 110s 141ms/step - loss: 0.6979\n",
      "Epoch 9/10\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.6745\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"i, Leonida, Leonie, Leonor, Leonora, Leo\"\n",
      "i, Leonida, Leonie, Leonor, Leonora, Leon, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"i, Leonida, Leonie, Leonor, Leonora, Leo\"\n",
      "i, Leonida, Leonie, Leonor, Leonora, Leon, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leone, Leoner, Leoney, Leonie, Leoney, Leonie, Leopie, Leop, Leop, Leop, Leop, Leopa, Leopa, Leopander, Leopardo, Leopardo, Leopande, Leopandine, Leopanten, Leopanter, Leop, Leopa, Leopan\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"i, Leonida, Leonie, Leonor, Leonora, Leo\"\n",
      "i, Leonida, Leonie, Leonor, Leonora, Leop, Leopard, Leopander, Leoparne, Leoper, Leopette, Leopette, Leop, Leopard, Leopan, Leopander, Leopantey, Leopantine, Leopante, Leoparr, Leopardine, Leopantes, Leoparris, Leopante, Leop, Leopa, Leopak, Leopat, Leopandelle, Leoper, Leopese, Leopette, Leop, Lepos, Lepott, Leppop, Lepott, Lepota, Lepon, Lepone, Lepport, Leppom, Leppo, Leppon, Leppon, Lepp, Leppa, Leppa, Leppa, Leppo, Lepore, Leppon, \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"i, Leonida, Leonie, Leonor, Leonora, Leo\"\n",
      "i, Leonida, Leonie, Leonor, Leonora, Leopaore, Leope, Leoppert, Leora, Leoriewe, Leorge, Leorge, Leorgle, Leorn, Leorger, Leorke, Leorkey, Leorley, Leop, Leop, Leope, Leopane, Leopantes, Leopenrie, Leopperte, Leep, Lepeau, Lepel, Lepetler, Lepette, Lephuit, Lepkin, Leply, Lepky, Lepley, Lepling, Lepling, Leplinger, Leplin, Lepling, Leplinger, Lepley, Lepling, Leplinger, Lepling, Leplington, Lelpuin, Lelp, Leleck, Lelefne, Lelfield, Lelf\n",
      "784/784 [==============================] - 103s 131ms/step - loss: 0.6745\n",
      "Epoch 10/10\n",
      "783/784 [============================>.] - ETA: 0s - loss: 0.6536\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"centyre, Mcerlean, Mceuen, Mcever, Mceve\"\n",
      "centyre, Mcerlean, Mceuen, Mcever, Mceverlick, Mcfreem, Mcfreever, Mcfreege, Mcfree, Mcfrein, Mcfrield, Mcfrie, Mcfrie, Mcfrie, Mcfrieder, Mcfried, Mcfrie, Mcfrie, Mcfrie, Mcfriell, Mcfried, Mcfriell, Mcfried, Mcfrie, Mcfrie, Mcfrie, Mcfrier, Mcfrie, Mcfrie, Mcfrie, Mcfriel, Mcfried, Mcfrien, Mcfrie, Mcfrie, Mcfrie, Mcfrien, Mcfrie, Mcfrie, Mcfrie, Mcfrie, Mcfrie, Mcfrieder, Mcfrie, Mcfrie, Mcfrie, Mcfrie, Mcfrier, Mcfrie, Mcfrich, Mcfr\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"centyre, Mcerlean, Mceuen, Mcever, Mceve\"\n",
      "centyre, Mcerlean, Mceuen, Mcever, Mceverling, Mcfreem, Mcfreever, Mcfreen, Mcfreen, Mcfreever, Mcfree, Mcfree, Mcfreicher, Mcfree, Mcfreever, Mcfreeger, Mcfreever, Mcfried, Mcfrie, Mcfrie, Mcfrie, Mcfriell, Mcfried, Mcfrie, Mcfrie, Mcfrom, Mcfrower, Mcribre, Mcrickle, Mcrickler, Mckoll, Mckon, Mckoner, Mckoner, Mckow, Mckow, Mckow, Mckowell, Mckowell, Mckowell, Mckone, Mckonnell, Mckonner, Mckor, Mckowski, Mckister, Mckitto, Mckitton, \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"centyre, Mcerlean, Mceuen, Mcever, Mceve\"\n",
      "centyre, Mcerlean, Mceuen, Mcever, Mcever, Mcerro, Mcerria, Mcerria, Mcerrie, Mcerrie, Mcerrig, Mcrier, Mcrierette, Mcriertino, Mcrierick, Mcrierton, Mcrierton, Mcrierton, Mcrierton, Mcriester, Mcriester, Mcrier, Mcrier, Mcriers, Mcrierick, Mcrier, Mcrier, Mcrierter, Mcrirgh, Mcrish, Mcrishard, Mcrish, Mcristell, Mcristop, Mcritto, Mcrittin, Mcritz, Mcriz, Mcrjes, Mcrjort, Mcrjorst, Mcrjorto, Mcroj, Mcklee, Mclock, Mclom, Mcmoner, Mcmon\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"centyre, Mcerlean, Mceuen, Mcever, Mceve\"\n",
      "centyre, Mcerlean, Mceuen, Mcever, Mcevery, Mcevi, Mceryche, Mcfreat, Mcfriedto, Mcfriell, Mcfrouet, Mcfrowe, Mcfrue, Mcfrowdanti, Mcwaston, Mcryball, Mcrian, Mcricrick, Mcrieckson, Mcrickert, Mcrie, Mckeckis, Mcleckin, Mcckg, Mclein, Mcleib, Mchlek, Mcleea, Mcleean, Mcleeich, Mcleibre, Mcleek, Mclees, Mcleeky, Mclefrin, Mclellette, Mclen, Mclenaugh, Mclentney, Mcleorty, Mclevey, Mclaeran, Mclorfy, Mclodick, Mcloi, Mclenkin, Mclenchick,\n",
      "784/784 [==============================] - 109s 139ms/step - loss: 0.6533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7ee455340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Nov  4 11:27:27 2022\n",
    "\n",
    "@author: gavinkoma\n",
    "\"\"\"\n",
    "#Import necessary libraries \n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "name_path = get_file('names.txt', origin='http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/other/names.txt')\n",
    "with io.open(name_path, encoding='utf-8') as f:\n",
    "    text = f.read() # make it all lowercase \n",
    "\n",
    "text = text.split()\n",
    "text = ', '.join(text)\n",
    "\n",
    "#alright lets train an lstm to generate names\n",
    "#how long does it take to train? \n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars: ' + str(len(chars)))\n",
    "char_indices = dict((c,i) for i,c in enumerate(chars))\n",
    "indices_char = dict((i,c) for i,c in enumerate(chars))\n",
    "\n",
    "#cut the text into semi-redundant sequences of maxlen characters\n",
    "#cut the text into a series of windows\n",
    "#each window is x length long\n",
    "#the window moves 3 steps forward each step.\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "# Turn these sentances into one-hot encoded vectors\n",
    "## For all words in the sentances, there is a one, else there is a zero in that index of the vector\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Done!')\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "print('Done!')\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.ma.log(preds)\n",
    "    preds = preds.filled(0)\n",
    "    preds = preds / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # clear_output()\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % (epoch+1))\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.4, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "epoch_val = [*range(1,10)]\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each epoch takes about ~30seconds to complete. For 10 epochs, it takes about five minutes total of training to complete. The names sound coherent but they are limited to the letters of the seed that the algorithm is presented with. Shuffling should take care of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
